{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e2ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Merge Process ---\n",
      "Loading Z-Train from: /home/pintokf/Projects/Microbium/Mouses/Locate_model/locate_Z_train_level_6.csv\n",
      "Loading Z-Test from: /home/pintokf/Projects/Microbium/Mouses/Locate_model/locate_Z_test_level_6.csv\n",
      "Combined Z Data Shape: (72, 11)\n",
      "ID column verified in Z data.\n",
      "Loading Metadata from: /home/pintokf/Projects/Microbium/Mouses/mouses_2_data/metadata.txt\n",
      "Loaded Metadata. Shape: (72, 11)\n",
      "Merging Z features with Metadata...\n",
      "--- Merge Complete ---\n",
      "Combined Z Samples: 72\n",
      "Metadata Samples: 72\n",
      "Final Merged Samples (Intersection): 72\n",
      "✅ Saved merged file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/merged_Z_level6_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "# Input 1: The Z-score test file from LOCATE\n",
    "z_test_path = '/home/pintokf/Projects/Microbium/Mouses/Locate_model/locate_Z_test_level_7.csv'\n",
    "# Input 2: The Z-score train file from LOCATE\n",
    "z_train_path = '/home/pintokf/Projects/Microbium/Mouses/Locate_model/locate_Z_train_level_7.csv'\n",
    "\n",
    "# Input 3: The metadata file\n",
    "metadata_path = \"/home/pintokf/Projects/Microbium/Mouses/mouses_2_data/metadata.txt\"\n",
    "\n",
    "# Output: The final merged file containing Z-features and Metadata\n",
    "output_path = \"/home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/merged_Z_level7_metadata.csv\"\n",
    "\n",
    "print(\"--- Starting Merge Process ---\")\n",
    "\n",
    "# 1. Load and Combine Z Data (Train + Test)\n",
    "try:\n",
    "    print(f\"Loading Z-Train from: {z_train_path}\")\n",
    "    df_train = pd.read_csv(z_train_path)\n",
    "\n",
    "    print(f\"Loading Z-Test from: {z_test_path}\")\n",
    "    df_test = pd.read_csv(z_test_path)\n",
    "\n",
    "    # Concatenate them (stacking rows) since columns are identical\n",
    "    df_z_all = pd.concat([df_train, df_test], ignore_index=True)\n",
    "    print(f\"Combined Z Data Shape: {df_z_all.shape}\")\n",
    "\n",
    "    # Verify ID column name in the Z data\n",
    "    if 'ID' in df_z_all.columns:\n",
    "        print(\"ID column verified in Z data.\")\n",
    "    elif 'SampleID' in df_z_all.columns:\n",
    "        print(\"Renaming 'SampleID' to 'ID' in Z data.\")\n",
    "        df_z_all.rename(columns={'SampleID': 'ID'}, inplace=True)\n",
    "    else:\n",
    "        # Fallback: assuming first column is ID if not named explicitly\n",
    "        print(f\"Warning: 'ID' column not found. Renaming first column '{df_z_all.columns[0]}' to 'ID'.\")\n",
    "        df_z_all.rename(columns={df_z_all.columns[0]: 'ID'}, inplace=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Z data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 2. Load Metadata\n",
    "try:\n",
    "    print(f\"Loading Metadata from: {metadata_path}\")\n",
    "    # Metadata is usually tab-separated\n",
    "    df_meta = pd.read_csv(metadata_path, sep='\\t')\n",
    "    print(f\"Loaded Metadata. Shape: {df_meta.shape}\")\n",
    "\n",
    "    # Standardize ID column name in Metadata\n",
    "    if '#SampleID' in df_meta.columns:\n",
    "        df_meta.rename(columns={'#SampleID': 'ID'}, inplace=True)\n",
    "    elif 'SampleID' in df_meta.columns:\n",
    "        df_meta.rename(columns={'SampleID': 'ID'}, inplace=True)\n",
    "\n",
    "    # Verify ID exists\n",
    "    if 'ID' not in df_meta.columns:\n",
    "        raise ValueError(\"Could not find ID column in metadata (expected '#SampleID' or 'SampleID')\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading metadata: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 3. Merge Tables\n",
    "# We use 'inner' merge to keep only samples that exist in BOTH (Z-features and Metadata)\n",
    "print(\"Merging Z features with Metadata...\")\n",
    "merged_df = pd.merge(df_z_all, df_meta, on='ID', how='inner')\n",
    "\n",
    "# 4. Save\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"--- Merge Complete ---\")\n",
    "print(f\"Combined Z Samples: {len(df_z_all)}\")\n",
    "print(f\"Metadata Samples: {len(df_meta)}\")\n",
    "print(f\"Final Merged Samples (Intersection): {len(merged_df)}\")\n",
    "print(f\"✅ Saved merged file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e901d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Total: 72\n",
      "Uncensored (Dead/Events): 22\n",
      "Censored (Alive/No Event): 50\n",
      "\n",
      "✅ Files saved successfully:\n",
      "1. /home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/locate_uncensored_level_6.csv\n",
      "2. /home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/locate_censored_level_6.csv\n"
     ]
    }
   ],
   "source": [
    "# === Split Data based on 'Death' column ===\n",
    "\n",
    "# 1. Create the Uncensored group (Death = yes)\n",
    "df_uncensored = merged_df[merged_df['Death'] == 'yes'].copy()\n",
    "\n",
    "# 2. Create the Censored group (Death = no)\n",
    "df_censored = merged_df[merged_df['Death'] == 'no'].copy()\n",
    "\n",
    "# === Verification ===\n",
    "print(f\"Original Total: {len(merged_df)}\")\n",
    "print(f\"Uncensored (Dead/Events): {len(df_uncensored)}\")\n",
    "print(f\"Censored (Alive/No Event): {len(df_censored)}\")\n",
    "\n",
    "# === Save to files ===\n",
    "output_dir = \"/home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate\"\n",
    "\n",
    "path_uncensored = f\"{output_dir}/locate_uncensored_level_7.csv\"\n",
    "path_censored = f\"{output_dir}/locate_censored_level_7.csv\"\n",
    "\n",
    "df_uncensored.to_csv(path_uncensored, index=False)\n",
    "df_censored.to_csv(path_censored, index=False)\n",
    "\n",
    "print(f\"\\n✅ Files saved successfully:\")\n",
    "print(f\"1. {path_uncensored}\")\n",
    "print(f\"2. {path_censored}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1ccf613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Uncensored (Dead) Data ---\n",
      "Columns remaining: ['ID', 'Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Cage', 'MiceName', 'SamplingDate', 'AgeMonths', 'DeathDate', 'DeathAgeMonths']\n",
      "Date Preview:\n",
      "           ID SamplingDate\n",
      "4   34-0_7-20   2020-07-01\n",
      "8   36-2_7-20   2020-07-01\n",
      "10  20-1_5-20   2020-05-01\n",
      "15  47-1_7-20   2020-07-01\n",
      "17  41-1_7-20   2020-07-01\n",
      "\n",
      "--- Processing Censored (Alive) Data ---\n",
      "Columns remaining: ['ID', 'Z_0', 'Z_1', 'Z_2', 'Z_3', 'Z_4', 'Z_5', 'Z_6', 'Z_7', 'Z_8', 'Z_9', 'Cage', 'MiceName', 'SamplingDate', 'AgeMonths', 'DeathDate', 'DeathAgeMonths']\n",
      "\n",
      "✅ Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_mouse_data(df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # === CRITICAL FIX 1: Reset Index ===\n",
    "    # Since 'ID' is currently the index, we must move it back to being a column.\n",
    "    # This fixes the print error AND ensures 'ID' is saved to the CSV later.\n",
    "    if df.index.name == 'ID':\n",
    "        df.reset_index(inplace=True)\n",
    "    \n",
    "    # === CRITICAL FIX 2: Clean column names ===\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # 1. Drop unnecessary columns\n",
    "    cols_to_drop = ['barcode', 'LinkerPrimerSequence', 'ReversePrimer', 'Death']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 2. Fix AgeMonths\n",
    "    if 'AgeMonths' in df.columns:\n",
    "        df['AgeMonths'] = df['AgeMonths'].astype(str).str.replace('_months', '', regex=False)\n",
    "        df['AgeMonths'] = pd.to_numeric(df['AgeMonths'], errors='coerce')\n",
    "    \n",
    "    # 3. Fix SamplingDate\n",
    "    if 'SamplingDate' in df.columns:\n",
    "        try:\n",
    "            def fix_date_format(val):\n",
    "                val_str = str(val).strip()\n",
    "                if '-' in val_str:\n",
    "                    parts = val_str.split('-')\n",
    "                    # parts[0] = \"20\" (Year), parts[1] = \"May\" (Month)\n",
    "                    return f\"01-{parts[1]}-20{parts[0]}\"\n",
    "                return val \n",
    "\n",
    "            df['SamplingDate'] = df['SamplingDate'].apply(fix_date_format)\n",
    "            df['SamplingDate'] = pd.to_datetime(df['SamplingDate'], format='%d-%b-%Y')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Warning: Date conversion failed: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Execution ===\n",
    "\n",
    "print(\"--- Processing Uncensored (Dead) Data ---\")\n",
    "df_uncensored_clean = process_mouse_data(df_uncensored)\n",
    "\n",
    "# Now this will work because 'ID' is a regular column again\n",
    "print(\"Columns remaining:\", list(df_uncensored_clean.columns))\n",
    "print(\"Date Preview:\")\n",
    "print(df_uncensored_clean[['ID', 'SamplingDate']].head())\n",
    "\n",
    "print(\"\\n--- Processing Censored (Alive) Data ---\")\n",
    "df_censored_clean = process_mouse_data(df_censored)\n",
    "print(\"Columns remaining:\", list(df_censored_clean.columns))\n",
    "\n",
    "# === Save Files ===\n",
    "# Since ID is now a column, index=False is CORRECT (we don't want a generic numeric index)\n",
    "df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "df_censored_clean.to_csv(path_censored, index=False)\n",
    "\n",
    "print(f\"\\n✅ Files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b743d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Uncensored Data (Dates & Diff) ---\n",
      "✅ Added 'diff' column.\n",
      "           ID  AgeMonths  DeathAgeMonths  diff\n",
      "4   34-0_7-20          4              13   270\n",
      "8   36-2_7-20          4              17   390\n",
      "10  20-1_5-20          4              12   240\n",
      "15  47-1_7-20          4              13   270\n",
      "17  41-1_7-20          4              16   360\n",
      "✅ Saved updated file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/locate_uncensored_level_6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Logic to fix DeathDate specific format ===\n",
    "# Input examples: \"05_21_b\", \"06_21\"\n",
    "# Output: 01-05-2021 (datetime object)\n",
    "def fix_death_date_format(val):\n",
    "    val_str = str(val).strip()\n",
    "    \n",
    "    if val_str == 'nan' or val_str == '':\n",
    "        return pd.NaT\n",
    "    \n",
    "    try:\n",
    "        # Split by underscore '_'\n",
    "        parts = val_str.split('_')\n",
    "        \n",
    "        # We need at least the first two parts (Month and Year)\n",
    "        if len(parts) >= 2:\n",
    "            month = parts[0]      # e.g., \"05\"\n",
    "            year_short = parts[1] # e.g., \"21\"\n",
    "            \n",
    "            # Construct the string \"01-MM-20YY\"\n",
    "            date_str = f\"01-{month}-20{year_short}\"\n",
    "            \n",
    "            # Convert to datetime\n",
    "            return pd.to_datetime(date_str, format='%d-%m-%Y')\n",
    "        else:\n",
    "            return pd.NaT\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error parsing date: {val} -> {e}\")\n",
    "        return pd.NaT\n",
    "\n",
    "# === Main Processing for Uncensored Data ===\n",
    "print(\"--- Processing Uncensored Data (Dates & Diff) ---\")\n",
    "\n",
    "# Ensure the dataframe exists\n",
    "if 'df_uncensored_clean' in locals():\n",
    "    \n",
    "    # 1. Apply DeathDate Fix\n",
    "    if 'DeathDate' in df_uncensored_clean.columns:\n",
    "        df_uncensored_clean['DeathDate'] = df_uncensored_clean['DeathDate'].apply(fix_death_date_format)\n",
    "\n",
    "    # 2. Calculate 'diff' Column\n",
    "    # Formula: (DeathAgeMonths - AgeMonths) * 30\n",
    "    if 'DeathAgeMonths' in df_uncensored_clean.columns and 'AgeMonths' in df_uncensored_clean.columns:\n",
    "        \n",
    "        # Ensure columns are numeric\n",
    "        df_uncensored_clean['DeathAgeMonths'] = pd.to_numeric(df_uncensored_clean['DeathAgeMonths'], errors='coerce')\n",
    "        df_uncensored_clean['AgeMonths'] = pd.to_numeric(df_uncensored_clean['AgeMonths'], errors='coerce')\n",
    "        \n",
    "        # Perform calculation\n",
    "        df_uncensored_clean['diff'] = (df_uncensored_clean['DeathAgeMonths'] - df_uncensored_clean['AgeMonths']) * 30\n",
    "        \n",
    "        print(\"✅ Added 'diff' column.\")\n",
    "        # Preview the new column\n",
    "        print(df_uncensored_clean[['ID', 'AgeMonths', 'DeathAgeMonths', 'diff']].head())\n",
    "    else:\n",
    "        print(\"❌ Error: Missing 'DeathAgeMonths' or 'AgeMonths' columns.\")\n",
    "\n",
    "    # 3. Save to file\n",
    "    df_uncensored_clean = df_uncensored_clean.drop('DeathAgeMonths', axis=1)\n",
    "    df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "    print(f\"✅ Saved updated file to: {path_uncensored}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error: df_uncensored_clean is not defined. Please run previous steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07003854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Censored Data (Columns & Dates) ---\n",
      "✅ Added 'diff' and 'DateEnd' columns.\n",
      "          ID  AgeMonths SamplingDate    DateEnd  diff\n",
      "0  29-1_5-20          4   2020-05-01 2021-07-01   420\n",
      "1  41-0_7-20          4   2020-07-01 2021-09-01   420\n",
      "2  38-2_7-20          4   2020-07-01 2021-09-01   420\n",
      "3  32-1_7-20          4   2020-07-01 2021-09-01   420\n",
      "5  42-1_5-20          2   2020-05-01 2021-09-01   480\n",
      "✅ Saved updated censored file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model_after_locate/preprocces_ratio_locate/locate_censored_level_6.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "print(\"--- Processing Censored Data (Columns & Dates) ---\")\n",
    "\n",
    "# Ensure the dataframe exists\n",
    "if 'df_censored_clean' in locals():\n",
    "    \n",
    "    # 1. Drop irrelevant columns for censored data\n",
    "    cols_to_drop = ['DeathDate', 'DeathAgeMonths']\n",
    "    df_censored_clean = df_censored_clean.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # Ensure numeric types for calculation\n",
    "    if 'AgeMonths' in df_censored_clean.columns:\n",
    "        df_censored_clean['AgeMonths'] = pd.to_numeric(df_censored_clean['AgeMonths'], errors='coerce')\n",
    "        \n",
    "        # 2. Calculate 'diff' column\n",
    "        # Formula: (18 - AgeMonths) * 30\n",
    "        df_censored_clean['diff'] = (18 - df_censored_clean['AgeMonths']) * 30\n",
    "        \n",
    "        # 3. Calculate 'DateEnd' column\n",
    "        # Logic: SamplingDate + (18 - AgeMonths) months\n",
    "        if 'SamplingDate' in df_censored_clean.columns:\n",
    "            # Ensure SamplingDate is datetime\n",
    "            df_censored_clean['SamplingDate'] = pd.to_datetime(df_censored_clean['SamplingDate'])\n",
    "            \n",
    "            # Define a helper function to add months per row\n",
    "            def add_months_to_reach_18(row):\n",
    "                try:\n",
    "                    months_to_add = int(18 - row['AgeMonths'])\n",
    "                    return row['SamplingDate'] + DateOffset(months=months_to_add)\n",
    "                except Exception as e:\n",
    "                    return pd.NaT\n",
    "\n",
    "            # Apply calculation\n",
    "            df_censored_clean['DateEnd'] = df_censored_clean.apply(add_months_to_reach_18, axis=1)\n",
    "            \n",
    "            # Ensure final format is datetime\n",
    "            df_censored_clean['DateEnd'] = pd.to_datetime(df_censored_clean['DateEnd'])\n",
    "            \n",
    "            print(\"✅ Added 'diff' and 'DateEnd' columns.\")\n",
    "            print(df_censored_clean[['ID', 'AgeMonths', 'SamplingDate', 'DateEnd', 'diff']].head())\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Error: 'SamplingDate' column missing.\")\n",
    "    else:\n",
    "        print(\"❌ Error: 'AgeMonths' column missing.\")\n",
    "\n",
    "    # 4. Save to file\n",
    "    df_censored_clean.to_csv(path_censored, index=False)\n",
    "    print(f\"✅ Saved updated censored file to: {path_censored}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error: df_censored_clean is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9f88a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncensored_clean.rename(columns={'SamplingDate': 'Date'}, inplace=True)\n",
    "df_censored_clean.rename(columns={'SamplingDate': 'Date'}, inplace=True)\n",
    "df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "df_censored_clean.to_csv(path_censored, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ratio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
