{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e2ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Merge Process ---\n",
      "Loaded Microbiome Data. Shape: (72, 36)\n",
      "Loaded Metadata. Shape: (72, 11)\n",
      "Metadata columns: ['ID', 'barcode', '             LinkerPrimerSequence', 'ReversePrimer', 'Cage', 'MiceName', 'SamplingDate', 'AgeMonths', 'Death', 'DeathDate', 'DeathAgeMonths']\n",
      "--- Merge Complete ---\n",
      "Original Microbiome Samples: 72\n",
      "Original Metadata Samples: 72\n",
      "Merged Samples (Intersection): 72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# === Paths ===\n",
    "# Input: The microbiome data we just created (Level 6)\n",
    "microbiome_path = \"/home/pintokf/Projects/Microbium/Mouses/MIPMLP_scripts/processed_subpca_level7.csv\"\n",
    "\n",
    "# Input: The metadata file\n",
    "metadata_path = \"/home/pintokf/Projects/Microbium/Mouses/mouses_2_data/metadata.txt\"\n",
    "\n",
    "# Output: The merged file ready for the next preprocessing steps\n",
    "#output_path = \"/home/pintokf/Projects/Microbium/Mouses/Ratio_model/merged_data_level6.csv\"\n",
    "\n",
    "print(\"--- Starting Merge Process ---\")\n",
    "\n",
    "# 1. Load Microbiome Data\n",
    "try:\n",
    "    df_micro = pd.read_csv(microbiome_path)\n",
    "    print(f\"Loaded Microbiome Data. Shape: {df_micro.shape}\")\n",
    "    # Verify ID exists\n",
    "    if 'ID' not in df_micro.columns:\n",
    "        raise ValueError(\"Column 'ID' not found in microbiome data!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading microbiome data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 2. Load Metadata\n",
    "try:\n",
    "    # Assuming metadata is tab-separated based on previous format\n",
    "    df_meta = pd.read_csv(metadata_path, sep='\\t')\n",
    "    print(f\"Loaded Metadata. Shape: {df_meta.shape}\")\n",
    "    \n",
    "    # Standardize ID column name in Metadata\n",
    "    # Common QIIME formats use '#SampleID' or 'SampleID'\n",
    "    if '#SampleID' in df_meta.columns:\n",
    "        df_meta.rename(columns={'#SampleID': 'ID'}, inplace=True)\n",
    "    elif 'SampleID' in df_meta.columns:\n",
    "        df_meta.rename(columns={'SampleID': 'ID'}, inplace=True)\n",
    "        \n",
    "    print(f\"Metadata columns: {list(df_meta.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading metadata: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 3. Merge Tables\n",
    "# We use 'inner' merge to keep only samples that have BOTH microbiome and metadata info\n",
    "merged_df = pd.merge(df_micro, df_meta, on='ID', how='inner')\n",
    "\n",
    "print(f\"--- Merge Complete ---\")\n",
    "print(f\"Original Microbiome Samples: {len(df_micro)}\")\n",
    "print(f\"Original Metadata Samples: {len(df_meta)}\")\n",
    "print(f\"Merged Samples (Intersection): {len(merged_df)}\")\n",
    "\n",
    "# 4. Save\n",
    "#merged_df.to_csv(output_path, index=False)\n",
    "#print(f\"✅ Saved merged file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved merged file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model/Preprocces_for_ratio_model/merged_data_level6.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"/home/pintokf/Projects/Microbium/Mouses/Ratio_model_microbium/Preprocces_for_ratio_model/merged_data_level7.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Saved merged file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e901d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Total: 72\n",
      "Uncensored (Dead/Events): 22\n",
      "Censored (Alive/No Event): 50\n",
      "\n",
      "✅ Files saved successfully:\n",
      "1. /home/pintokf/Projects/Microbium/Mouses/Ratio_model/Preprocces_for_ratio_model/data_level6_uncensored.csv\n",
      "2. /home/pintokf/Projects/Microbium/Mouses/Ratio_model/Preprocces_for_ratio_model/data_level6_censored.csv\n"
     ]
    }
   ],
   "source": [
    "# === Split Data based on 'Death' column ===\n",
    "\n",
    "# 1. Create the Uncensored group (Death = yes)\n",
    "df_uncensored = merged_df[merged_df['Death'] == 'yes'].copy()\n",
    "\n",
    "# 2. Create the Censored group (Death = no)\n",
    "df_censored = merged_df[merged_df['Death'] == 'no'].copy()\n",
    "\n",
    "# === Verification ===\n",
    "print(f\"Original Total: {len(merged_df)}\")\n",
    "print(f\"Uncensored (Dead/Events): {len(df_uncensored)}\")\n",
    "print(f\"Censored (Alive/No Event): {len(df_censored)}\")\n",
    "\n",
    "# === Save to files ===\n",
    "output_dir = \"/home/pintokf/Projects/Microbium/Mouses/Ratio_model_microbium/Preprocces_for_ratio_model\"\n",
    "\n",
    "path_uncensored = f\"{output_dir}/data_level7_uncensored.csv\"\n",
    "path_censored = f\"{output_dir}/data_level7_censored.csv\"\n",
    "\n",
    "df_uncensored.to_csv(path_uncensored, index=False)\n",
    "df_censored.to_csv(path_censored, index=False)\n",
    "\n",
    "print(f\"\\n✅ Files saved successfully:\")\n",
    "print(f\"1. {path_uncensored}\")\n",
    "print(f\"2. {path_censored}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1ccf613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Uncensored (Dead) Data ---\n",
      "Columns remaining: ['ID', 'k__Bacteria_0;p__;c__;o__;f__;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales_0;f__;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Bacteroides_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Porphyromonadaceae;g__Parabacteroides_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Prevotellaceae;g__Prevotella_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae_0;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae;g__Alistipes_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__S24-7_0;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__[Odoribacteraceae];g__Odoribacter_0;s__', 'k__Bacteria;p__Cyanobacteria;c__4C0d-2;o__YS2_0;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Bacillales;f__Staphylococcaceae;g__Staphylococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Lactobacillaceae;g__Lactobacillus_0;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Turicibacterales;f__Turicibacteraceae;g__Turicibacter_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia_0;o__;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales_0;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Dehalobacteriaceae;g__Dehalobacterium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Clostridium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Coprococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Dorea_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__[Ruminococcus]_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Peptococcaceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Butyricicoccus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Clostridium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Oscillospira_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Ruminococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__[Mogibacteriaceae]_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o__Erysipelotrichales;f__Erysipelotrichaceae;g__Allobaculum_0;s__', 'k__Bacteria;p__Proteobacteria_0;c__;o__;f__;g__;s__', 'k__Bacteria;p__Proteobacteria;c__Betaproteobacteria;o__Burkholderiales;f__Alcaligenaceae;g__Sutterella_0;s__', 'k__Bacteria;p__Proteobacteria;c__Deltaproteobacteria;o__Desulfovibrionales;f__Desulfovibrionaceae;g__Bilophila_0;s__', 'k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Enterobacteriales;f__Enterobacteriaceae_0;g__;s__', 'k__Bacteria;p__Tenericutes;c__Mollicutes;o__Anaeroplasmatales;f__Anaeroplasmataceae;g__Anaeroplasma_0;s__', 'k__Bacteria;p__Verrucomicrobia;c__Verrucomicrobiae;o__Verrucomicrobiales;f__Verrucomicrobiaceae;g__Akkermansia_0;s__', 'Cage', 'MiceName', 'SamplingDate', 'AgeMonths', 'DeathDate', 'DeathAgeMonths']\n",
      "Date Preview:\n",
      "           ID SamplingDate\n",
      "1   14-1_5-20   2020-05-01\n",
      "7   20-1_5-20   2020-05-01\n",
      "8   21-1_5-20   2020-05-01\n",
      "15  24-0_5-20   2020-05-01\n",
      "17  24-2_5-20   2020-05-01\n",
      "\n",
      "--- Processing Censored (Alive) Data ---\n",
      "Columns remaining: ['ID', 'k__Bacteria_0;p__;c__;o__;f__;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales_0;f__;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Bacteroidaceae;g__Bacteroides_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Porphyromonadaceae;g__Parabacteroides_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Prevotellaceae;g__Prevotella_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae_0;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__Rikenellaceae;g__Alistipes_0;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__S24-7_0;g__;s__', 'k__Bacteria;p__Bacteroidetes;c__Bacteroidia;o__Bacteroidales;f__[Odoribacteraceae];g__Odoribacter_0;s__', 'k__Bacteria;p__Cyanobacteria;c__4C0d-2;o__YS2_0;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Bacillales;f__Staphylococcaceae;g__Staphylococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Lactobacillales;f__Lactobacillaceae;g__Lactobacillus_0;s__', 'k__Bacteria;p__Firmicutes;c__Bacilli;o__Turicibacterales;f__Turicibacteraceae;g__Turicibacter_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia_0;o__;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales_0;f__;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Dehalobacteriaceae;g__Dehalobacterium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Clostridium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Coprococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__Dorea_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Lachnospiraceae;g__[Ruminococcus]_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Peptococcaceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Butyricicoccus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Clostridium_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Oscillospira_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__Ruminococcaceae;g__Ruminococcus_0;s__', 'k__Bacteria;p__Firmicutes;c__Clostridia;o__Clostridiales;f__[Mogibacteriaceae]_0;g__;s__', 'k__Bacteria;p__Firmicutes;c__Erysipelotrichi;o__Erysipelotrichales;f__Erysipelotrichaceae;g__Allobaculum_0;s__', 'k__Bacteria;p__Proteobacteria_0;c__;o__;f__;g__;s__', 'k__Bacteria;p__Proteobacteria;c__Betaproteobacteria;o__Burkholderiales;f__Alcaligenaceae;g__Sutterella_0;s__', 'k__Bacteria;p__Proteobacteria;c__Deltaproteobacteria;o__Desulfovibrionales;f__Desulfovibrionaceae;g__Bilophila_0;s__', 'k__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Enterobacteriales;f__Enterobacteriaceae_0;g__;s__', 'k__Bacteria;p__Tenericutes;c__Mollicutes;o__Anaeroplasmatales;f__Anaeroplasmataceae;g__Anaeroplasma_0;s__', 'k__Bacteria;p__Verrucomicrobia;c__Verrucomicrobiae;o__Verrucomicrobiales;f__Verrucomicrobiaceae;g__Akkermansia_0;s__', 'Cage', 'MiceName', 'SamplingDate', 'AgeMonths', 'DeathDate', 'DeathAgeMonths']\n",
      "\n",
      "✅ Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_mouse_data(df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # === CRITICAL FIX: Clean column names ===\n",
    "    # This removes the huge whitespace from '             LinkerPrimerSequence'\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # 1. Drop unnecessary columns\n",
    "    # Now that the columns are stripped, 'LinkerPrimerSequence' will match exactly\n",
    "    cols_to_drop = ['barcode', 'LinkerPrimerSequence', 'ReversePrimer', 'Death']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # 2. Fix AgeMonths (remove '_months', convert to number)\n",
    "    if 'AgeMonths' in df.columns:\n",
    "        df['AgeMonths'] = df['AgeMonths'].astype(str).str.replace('_months', '', regex=False)\n",
    "        df['AgeMonths'] = pd.to_numeric(df['AgeMonths'], errors='coerce')\n",
    "    \n",
    "    # 3. Fix SamplingDate\n",
    "    # Logic: \"20-May\" -> Day: 01, Month: May, Year: 2020\n",
    "    if 'SamplingDate' in df.columns:\n",
    "        try:\n",
    "            def fix_date_format(val):\n",
    "                val_str = str(val).strip()\n",
    "                if '-' in val_str:\n",
    "                    parts = val_str.split('-')\n",
    "                    # parts[0] = \"20\" (Year)\n",
    "                    # parts[1] = \"May\" (Month)\n",
    "                    year_suffix = parts[0]\n",
    "                    month_name = parts[1]\n",
    "                    # Construct string: \"01-May-2020\"\n",
    "                    return f\"01-{month_name}-20{year_suffix}\"\n",
    "                return val # Return original if format is unexpected\n",
    "\n",
    "            # Apply the string formatting\n",
    "            df['SamplingDate'] = df['SamplingDate'].apply(fix_date_format)\n",
    "            \n",
    "            # Convert to actual datetime object\n",
    "            df['SamplingDate'] = pd.to_datetime(df['SamplingDate'], format='%d-%b-%Y')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Warning: Date conversion failed: {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# === Execution ===\n",
    "\n",
    "print(\"--- Processing Uncensored (Dead) Data ---\")\n",
    "# Ensure df_uncensored exists from previous cells\n",
    "df_uncensored_clean = process_mouse_data(df_uncensored)\n",
    "\n",
    "# Debug prints to verify\n",
    "print(\"Columns remaining:\", list(df_uncensored_clean.columns))\n",
    "print(\"Date Preview:\")\n",
    "print(df_uncensored_clean[['ID', 'SamplingDate']].head())\n",
    "\n",
    "\n",
    "print(\"\\n--- Processing Censored (Alive) Data ---\")\n",
    "# Ensure df_censored exists from previous cells\n",
    "df_censored_clean = process_mouse_data(df_censored)\n",
    "#df_censored_clean = df_censored_clean.drop('Cage', axis=1)\n",
    "print(\"Columns remaining:\", list(df_censored_clean.columns))\n",
    "\n",
    "\n",
    "# === Save Files ===\n",
    "df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "df_censored_clean.to_csv(path_censored, index=False)\n",
    "\n",
    "print(f\"\\n✅ Files saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b743d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Uncensored Data (Dates & Diff) ---\n",
      "✅ Added 'diff' column.\n",
      "           ID  AgeMonths  DeathAgeMonths  diff\n",
      "1   14-1_5-20          4              17   390\n",
      "7   20-1_5-20          4              12   240\n",
      "8   21-1_5-20          4              15   330\n",
      "15  24-0_5-20          4              17   390\n",
      "17  24-2_5-20          4              17   390\n",
      "✅ Saved updated file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model/Preprocces_for_ratio_model/data_level6_uncensored.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Logic to fix DeathDate specific format ===\n",
    "# Input examples: \"05_21_b\", \"06_21\"\n",
    "# Output: 01-05-2021 (datetime object)\n",
    "def fix_death_date_format(val):\n",
    "    val_str = str(val).strip()\n",
    "    \n",
    "    if val_str == 'nan' or val_str == '':\n",
    "        return pd.NaT\n",
    "    \n",
    "    try:\n",
    "        # Split by underscore '_'\n",
    "        parts = val_str.split('_')\n",
    "        \n",
    "        # We need at least the first two parts (Month and Year)\n",
    "        if len(parts) >= 2:\n",
    "            month = parts[0]      # e.g., \"05\"\n",
    "            year_short = parts[1] # e.g., \"21\"\n",
    "            \n",
    "            # Construct the string \"01-MM-20YY\"\n",
    "            date_str = f\"01-{month}-20{year_short}\"\n",
    "            \n",
    "            # Convert to datetime\n",
    "            return pd.to_datetime(date_str, format='%d-%m-%Y')\n",
    "        else:\n",
    "            return pd.NaT\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error parsing date: {val} -> {e}\")\n",
    "        return pd.NaT\n",
    "\n",
    "# === Main Processing for Uncensored Data ===\n",
    "print(\"--- Processing Uncensored Data (Dates & Diff) ---\")\n",
    "\n",
    "# Ensure the dataframe exists\n",
    "if 'df_uncensored_clean' in locals():\n",
    "    \n",
    "    # 1. Apply DeathDate Fix\n",
    "    if 'DeathDate' in df_uncensored_clean.columns:\n",
    "        df_uncensored_clean['DeathDate'] = df_uncensored_clean['DeathDate'].apply(fix_death_date_format)\n",
    "\n",
    "    # 2. Calculate 'diff' Column\n",
    "    # Formula: (DeathAgeMonths - AgeMonths) * 30\n",
    "    if 'DeathAgeMonths' in df_uncensored_clean.columns and 'AgeMonths' in df_uncensored_clean.columns:\n",
    "        \n",
    "        # Ensure columns are numeric\n",
    "        df_uncensored_clean['DeathAgeMonths'] = pd.to_numeric(df_uncensored_clean['DeathAgeMonths'], errors='coerce')\n",
    "        df_uncensored_clean['AgeMonths'] = pd.to_numeric(df_uncensored_clean['AgeMonths'], errors='coerce')\n",
    "        \n",
    "        # Perform calculation\n",
    "        df_uncensored_clean['diff'] = (df_uncensored_clean['DeathAgeMonths'] - df_uncensored_clean['AgeMonths']) * 30\n",
    "        \n",
    "        print(\"✅ Added 'diff' column.\")\n",
    "        # Preview the new column\n",
    "        print(df_uncensored_clean[['ID', 'AgeMonths', 'DeathAgeMonths', 'diff']].head())\n",
    "    else:\n",
    "        print(\"❌ Error: Missing 'DeathAgeMonths' or 'AgeMonths' columns.\")\n",
    "\n",
    "    # 3. Save to file\n",
    "    df_uncensored_clean = df_uncensored_clean.drop('DeathAgeMonths', axis=1)\n",
    "    df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "    print(f\"✅ Saved updated file to: {path_uncensored}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error: df_uncensored_clean is not defined. Please run previous steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07003854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Censored Data (Columns & Dates) ---\n",
      "✅ Added 'diff' and 'DateEnd' columns.\n",
      "          ID  AgeMonths SamplingDate    DateEnd  diff\n",
      "0  14-0_5-20          4   2020-05-01 2021-07-01   420\n",
      "2  14-2_5-20          4   2020-05-01 2021-07-01   420\n",
      "3  15-1_5-20          4   2020-05-01 2021-07-01   420\n",
      "4  18-1_5-20          4   2020-05-01 2021-07-01   420\n",
      "5  18-2_5-20          4   2020-05-01 2021-07-01   420\n",
      "✅ Saved updated censored file to: /home/pintokf/Projects/Microbium/Mouses/Ratio_model/Preprocces_for_ratio_model/data_level6_censored.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "print(\"--- Processing Censored Data (Columns & Dates) ---\")\n",
    "\n",
    "# Ensure the dataframe exists\n",
    "if 'df_censored_clean' in locals():\n",
    "    \n",
    "    # 1. Drop irrelevant columns for censored data\n",
    "    cols_to_drop = ['DeathDate', 'DeathAgeMonths']\n",
    "    df_censored_clean = df_censored_clean.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # Ensure numeric types for calculation\n",
    "    if 'AgeMonths' in df_censored_clean.columns:\n",
    "        df_censored_clean['AgeMonths'] = pd.to_numeric(df_censored_clean['AgeMonths'], errors='coerce')\n",
    "        \n",
    "        # 2. Calculate 'diff' column\n",
    "        # Formula: (18 - AgeMonths) * 30\n",
    "        df_censored_clean['diff'] = (18 - df_censored_clean['AgeMonths']) * 30\n",
    "        \n",
    "        # 3. Calculate 'DateEnd' column\n",
    "        # Logic: SamplingDate + (18 - AgeMonths) months\n",
    "        if 'SamplingDate' in df_censored_clean.columns:\n",
    "            # Ensure SamplingDate is datetime\n",
    "            df_censored_clean['SamplingDate'] = pd.to_datetime(df_censored_clean['SamplingDate'])\n",
    "            \n",
    "            # Define a helper function to add months per row\n",
    "            def add_months_to_reach_18(row):\n",
    "                try:\n",
    "                    months_to_add = int(18 - row['AgeMonths'])\n",
    "                    return row['SamplingDate'] + DateOffset(months=months_to_add)\n",
    "                except Exception as e:\n",
    "                    return pd.NaT\n",
    "\n",
    "            # Apply calculation\n",
    "            df_censored_clean['DateEnd'] = df_censored_clean.apply(add_months_to_reach_18, axis=1)\n",
    "            \n",
    "            # Ensure final format is datetime\n",
    "            df_censored_clean['DateEnd'] = pd.to_datetime(df_censored_clean['DateEnd'])\n",
    "            \n",
    "            print(\"✅ Added 'diff' and 'DateEnd' columns.\")\n",
    "            print(df_censored_clean[['ID', 'AgeMonths', 'SamplingDate', 'DateEnd', 'diff']].head())\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Error: 'SamplingDate' column missing.\")\n",
    "    else:\n",
    "        print(\"❌ Error: 'AgeMonths' column missing.\")\n",
    "\n",
    "    # 4. Save to file\n",
    "    df_censored_clean.to_csv(path_censored, index=False)\n",
    "    print(f\"✅ Saved updated censored file to: {path_censored}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Error: df_censored_clean is not defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9f88a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncensored_clean.rename(columns={'SamplingDate': 'Date'}, inplace=True)\n",
    "df_censored_clean.rename(columns={'SamplingDate': 'Date'}, inplace=True)\n",
    "df_uncensored_clean.to_csv(path_uncensored, index=False)\n",
    "df_censored_clean.to_csv(path_censored, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
